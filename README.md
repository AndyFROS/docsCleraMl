# docsCleraMl

# Основная терминология

#### Функционал ClearML позволяет:

* Отслеживать метрики, гиперпараметры и артефакты машинного обучения.

* Хранить и предоставлять по запросу модели.

* Хранить датасеты.

* Визуально сравнивать эксперименты.

* Воспроизводить эксперименты.

* Автоматически логировать все действия.

* Настраивать пайплайны обработки данных.

* Визуализировать результаты.

#### Технически в ClearML принята следующая структура:

В ClearML принята следующая структура сущностей: **Проект** → _(опционально)_ **подпроект** → **Задача** (Task) → **Артефакты**.

- **Проект** – верхнеуровневая категория, объединяющая набор экспериментов по определённой теме или продукту.
- **Подпроект** – вложенный проект внутри основного, для дополнительной организации экспериментов (например, по подзадачам).
- **Задача (Task)** – минимальная единица эксперимента в ClearML. Задача содержит код эксперимента, параметры, метрики, артефакты и логи. С точки зрения прикладного использования задачей может быть, например, R&D-эксперимент (подбор гиперпараметров, проба новой архитектуры модели и т.п.) или периодическое переобучение модели на новых данных.
- **Артефакт** – любой объект (файл, данные, модель и пр.), сохраненный в рамках задачи. Артефакты обычно представляют входные датасеты, сгенерированные результаты, обученные модели и т.д., которые сохраняются для последующего анализа и воспроизведения эксперимента.

Каждая задача имеет атрибут типа. Основные **типы задач** в терминологии ClearML:

- _training_ (обучение модели) – тип по умолчанию для новых задач.
- _testing_ (тестирование, например, оценка производительности модели).
- _inference_ (инференс – применение модели для предсказаний).
- _data_processing_ (обработка данных).
- _application_ (прикладное использование, произвольные приложения).
- _monitor_ (мониторинг процессов).
- _controller_ (контролирующая задача, определяющая логику работы других задач).
- _optimizer_ (оптимизация гиперпараметров).
- _service_ (служебные задачи).
- _qc_ (quality control – контроль качества, например A/B тестирование).
- _custom_ (произвольный тип, если не подходит ни один из выше).

Выбранный тип задачи отображается в списке экспериментов в интерфейсе для удобства классификации.


#### Основные компоненты:

**Проект (Project)** – логическая единица для группировки задач.

**Задача (Task)** – основной объект эксперимента (обучение, обработка и пр.).

**Агент (Agent)** – сервис для удалённого выполнения задач.

**Очередь (Queue)** – список задач для исполнения агентами.

**Артефакт (Artifact)** – сохранённый результат выполнения задачи.

**Модель (Model)** – артефакт, представляющий обученную ML-модель.

**Dataset (набор данных)** – версионированный набор файлов/данных.

**Pipeline (конвейер)** – оркестрация нескольких задач в последовательный процесс.

# 1. Подключение пользователя

Для того, чтобы была возможность подключится к ClearML, необходимо проинициализировать пользователя
`clearml init`
Далее будет предложено вставить базовую конфигурацию, она выглядит следующим образом

```json
api {
  verify_certificate = False
  web_server: https://domain.name.clearML/
  api_server: https://domain.name.clearML:8008
  credentials {
    "access_key" = "user_access_key"
    "secret_key" = "user_secret_key"
  }
}
```
Будет создан clearml.conf файл.
Для подключения к S3 хранилищу, в этот файл нужно добавить следующее

```json
s3 {
            # default, used for any bucket not specified below
            key: "key_aws_storage_credentials"
            secret: "secret_key_aws_storage_credentials"
            region: "us-east-1"
    
            credentials: [
                {
                    # This will apply to all buckets in this host (unless key/value is specifically provided for a given bucket)
                    host: "domain.name.s3:port"
                    key: "Key_aws_storage_credentials"
                    secret: "secret_key_aws_storage_credentials"
                    multipart: false
                    secure: true
                    verify: "/path/to/certs/clearMLcert.crt" # или "/path/to/ca/bundle.crt" OR "https://url/of/ca/bundle.crt" или false чтобы не проверять                    
                }
            ]
        } 
```


Для подключения в jupyter notebook
```python
%env CLEARML_WEB_HOST=https://clear-ml.oanz.ds.lab/
%env CLEARML_API_HOST=https://clear-ml.oanz.ds.lab:8008
%env CLEARML_API_ACCESS_KEY=KUO7SBPD1ABQQIWPBMR5C1VONAMQ23
%env CLEARML_API_SECRET_KEY=N0xGBtA_chD9eTPf1EX-_qhtjHbVZpUArzmKYT6ryh8AJwcJw0K1C3dO2krd7qQFvC8
```

Если появляется ошибка 

```
Retrying (Retry(total=239, connect=240, read=240, redirect=240, status=240)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1007)'))': /auth.login
```
То необходимо явно указать сертификат, в среде исполнения
```python
import os
os.environ["REQUESTS_CA_BUNDLE"] = "certs/dslab.crt"
os.environ["SSL_CERT_FILE"] = "certs/dslab.crt"
```
  

## Работа с проектами

**Проекты** в ClearML служат для организации экспериментов. Cтруктурированное дерево проектов, каждый проект – это по сути папка, содержащая набор задач (экспериментов).

- Создать новый проект можно через веб-интерфейс ClearML: на вкладке **Projects** нажав кнопку _New Project_ и указав имя. Также проекты можно создавать программно – при инициализации новой задачи в несуществующем проекте, ClearML автоматически создаст проект с указанным именем.

- **Подпроекты**: ClearML поддерживает вложенность проектов. В веб-интерфейсе можно указать родительский проект при создании нового, тем самым образуя иерархию. Например, можно завести основной проект _Image Classification_, а внутри него подпроекты _Cats vs Dogs_, _MNIST experiments_ и т.д. В коде аналогичного эффекта можно достичь, указав имя проекта со слешом (например, `project_name="Image Classification/Cats vs Dogs"` при создании задачи).

- **Просмотр и управление**: В интерфейсе на странице проекта можно увидеть таблицу всех задач, принадлежащих этому проекту (и вложенным подпроектам). Там отображаются колонки с разными свойствами задачи: статус, теги, результаты метрик, время выполнения и пр. Эти колонки настраиваются – можно добавить, к примеру, вывод конкретной метрики для быстрого сравнения между задачами. В рамках проекта можно выполнять групповые операции над задачами: сравнение, копирование, перемещение в другой проект, удаление и др.

## Задачи

**Задача** (Task) представляет единичный эксперимент или выполняемый код. Создание задачи – первый шаг к тому, чтобы ClearML начал отслеживать ваш эксперимент. Обычно разработчик вставляет несколько строк с ClearML SDK в свой ML-скрипт, чтобы инициализировать задачу и логировать результаты. Рассмотрим типичный рабочий процесс:

1. **Инициализация задачи**. В начале необходимо создать задачу и связать её с ClearML. Это делается вызовом `Task.init()` из пакета `clearml`.

```python
from clearml import Task
task = Task.init(project_name="Demo Project", task_name="Experiment 1", tags=["baseline"])
```

При вызове `Task.init()` происходят следующие вещи:

- На сервере создаётся новая задача в указанном проекте (если проекта не было, он будет создан). Задаче присваиваются уникальный ID и указанные вами имя и теги.

- SDK начинает отслеживание окружения: фиксируется версия используемого `clearml` SDK, имена и версии всех загруженных пакетов Python, а также собирается информация о системе (CPU/GPU, ОС и пр.). Если вы выполняете код в Jupyter Notebook, то ClearML сохранит текущий ноутбук и прикрепит его как HTML-отчет к задаче.

- Все последующие действия в коде могут автоматически или вручную логироваться в эту задачу (метрики, параметры, артефакты и т.д.).


> _Примечание:_ По умолчанию создаётся задача типа _training_. Тип можно изменить, передав параметр `task_type` в `Task.init(...)` (например, `task_type="testing"`), – это влияет только на отображение пиктограммы в UI и не меняет функциональность задачи.

2. **Логирование гиперпараметров и конфигураций**. Очень важно задокументировать, с какими параметрами запускался эксперимент (например, размеры слоёв, скорость обучения, случайный seed и т.п.). ClearML позволяет легко сохранять параметры:

- **Связывание объекта конфигурации**: можно передать в `Task.init()` параметр
	`configuration` или вызвать `task.connect()` для словаря или dataclass с параметрами.
	Этот вызов сохранит словарь `config` как набор гиперпараметров, связанных с 
	задачей. В интерфейсе они появятся на вкладке **Configuration** или 
	**Hyperparameters**.

```python
config = {"lr": 0.001, "batch_size": 32, "augmentations": True}
task.connect(config)
```

-  **Именованные конфиги**: При необходимости можно логировать несколько разных конфигураций (например, отдельный конфиг модели, конфиг данных). Для этого `task.connect()` принимает опциональный `name`. Либо используйте метод `Task.update_configuration(name, config_dict)`.

Кроме гиперпараметров, ClearML автоматически сохраняет некоторую информацию о среде: например, путь запущенного скрипта, Git-репозиторий и хеш коммита (если вы запускаете код из репозитория и у вас настроен Git), переменные окружения и пр. Это помогает в воспроизведении эксперимента.

3. **Логирование метрик**. В ходе эксперимента, как правило, вычисляются метрики качества модели (точность, loss, ROC AUC и т.д.) на разных этапах обучения. Чтобы эти значения автоматически собирались и визуализировались, можно использовать логгер ClearML. Получить его можно через `task.get_logger()` или обратиться к глобальному логгеру для текущей задачи:


```python
logger = task.get_logger()
for epoch in range(1, 6):
    train_acc = train_epoch(...)  # функция обучения на эпохе
    val_acc = validate(...)       # функция валидации
    # Логируем метрики за текущую эпоху:
    logger.report_scalar(title="Accuracy", series="Train", value=train_acc, iteration=epoch)
    logger.report_scalar(title="Accuracy", series="Validation", value=val_acc, iteration=epoch)
```


В приведённом примере на сервер будут отправлены две метрики (Accuracy/Train и Accuracy/Validation) со значениями по итерациям (здесь iteration используется как номер эпохи). В веб-интерфейсе на вкладке **Scalars** появятся графики этих метрик. Методы `report_scalar` удобны для числовых показателей. ClearML Logger также поддерживает:

- `report_plot` для произвольных графиков (линий, гистограмм и т.п.).
- `report_image` для сохранения изображений (например, примеры входных данных, графики потерь).
- `report_table` для таблиц (например, сводка результатов).
- `report_text` для текстовых логов или Markdown.



Помимо явного вызова логгера, ClearML интегрируется с популярными ML-библиотеками. Например, при использовании TensorFlow или PyTorch Lightning, их встроенные логи (tf.summary, tensorboardX) могут автоматически отображаться в ClearML. Аналогично, stdout вашего скрипта (print-ы) будет сохранён и доступен в логах задачи.

4. **Завершение задачи**. По окончании эксперимента рекомендуется явно закрыть задачу, чтобы зафиксировать её статус как завершённый:

`task.close()`


Этот вызов сообщит серверу, что задача завершена (status = Completed). Если вы этого не сделаете, задача может остаться в статусе "running" или "in progress". Закрытие важно при удалённом выполнении, но и для локальных запусков это хорошая практика.


После выполнения кода с интеграцией ClearML, вы сможете зайти в веб-интерфейс и найти созданную задачу в соответствующем проекте. Там будет доступна вся собранная информация:

- Вкладка **Info** с общей информацией (имя, проект, статус, теги, тип, продолжительность и т.д.).
- **Configuration / Hyperparameters** – ваши сохранённые параметры и конфиги.
- **Scalars / Plots** – графики метрик по итерациям.
- **Console** – консольный вывод вашего программы.
- **Artifacts** – файлы и артефакты (о них далее).
- **Execution** – детали окружения: путь скрипта, Git commit, используемые пакеты (Requirements) и пр.

Кроме того, ClearML позволяет:

- **Сравнивать задачи** – выбрать несколько задач и нажать _Compare_, после чего UI покажет сравнение метрик, параметров и даже графическое наложение кривых.
- **Клонировать/воспроизводить задачу** – на базе существующей можно создать копию (например, чтобы запустить с другими данными), либо запустить повторно ту же самую (полностью воспроизведя окружение).

## Артефакты

Артефакты – это данные, которые ваша задача сохраняет для дальнейшего использования или анализа. Они могут быть различного типа и размера:

- Предобработанные датасеты или их фрагменты.
- Графики или отчёты в формате HTML/CSV.
- Лучшие найденные гиперпараметры, сохранённые как JSON.
- Весовые коэффициенты модели (файлы моделей).
- Лог-файлы, снимки Jupyter ноутбука и пр.

**Автоматические артефакты**: ClearML старается сохранить полезные результаты без дополнительного кода. Например, если вы запускали задачу в Jupyter Notebook, после выполнения `Task.init()` весь ноутбук (включая исходный код, Markdown и вывод) будет сохранён как HTML-файл и прикреплён к задаче (его можно найти на вкладке **Artifacts** -> Jupyter Notebook). Также, если ваш код находится под Git, snapshot репозитория (список файлов с хешами) сохраняется как artifact типа "Source".

**Ручное сохранение артефактов**: Для любых данных, полученных в процессе эксперимента, вы можете вызвать метод SDK, чтобы зафиксировать их в ClearML. Проще всего использовать `Task.upload_artifact()`:

```python
# Предположим, task = Task.current_task() уже создан
result_df.to_csv("results.csv", index=False)
task.upload_artifact(name="Inference Results", artifact_object="results.csv")
```


В этом примере мы сохранили pandas DataFrame локально в файл CSV, а затем загрузили этот файл на сервер ClearML как артефакт с именем "Inference Results". После завершения задачи данный файл будет доступен через UI (его можно просматривать прямо в браузере или скачать).

Метод `upload_artifact` умеет сохранять:

- Строки и числа (они будут упакованы в файл .txt).
- Словари, списки, numpy array и другие Python-объекты (они будут сериализованы, например через pickle или npy).
- Локальные файлы или даже папки (укажите `artifact_object` путём к файлу или директории, директория будет заархивирована).
- Также можно указать `metadata` – словарь с метаданными (опционально).

Все артефакты задачи доступны через `Task.get_local_copy()` или `Task.artifacts` (словарь с метаданными) при доступе к задаче из кода. Таким образом, одна задача может загрузить артефакт, а другая – загрузить его и использовать, зная ID задачи и имя артефакта. Это способствует воспроизводимости и повторному использованию результатов.

> **Примечание:** Для больших файлов можно настроить внешний бэкенд хранения (S3, Google Cloud Storage, Azure Blob или сетевое хранилище). ClearML-сервер будет хранить только ссылки, а сами артефакты – во внешнем хранилище. Конфигурация хранилища выполняется в `clearml.conf` (секция `storage`).

## Очереди и агенты

Одна из возможностей ClearML – **удалённое выполнение экспериментов**. Это реализовано через систему очередей задач и агентов-исполнителей. Эта составляющая превращает ClearML из инструмента трекинга в полноценную MLOps-платформу, позволяющую автоматически запускать эксперименты на выделенных серверах или кластерах.

**Очередь (Queue)** – это именованный канал, куда ставятся задачи для последующего выполнения. Само по себе помещение задачи в очередь не запускает её, нужен агент, который эту задачу возьмёт. Но для пользователя это выглядит как "отправить задачу на выполнение в среду X". Вы можете создавать произвольное количество очередей. По умолчанию в ClearML есть очередь _default_. Часто имеет смысл завести очереди по типам ресурсов, например: _cpu_, _gpu_, _low-priority_, _high-mem_ и т.д. – названия произвольны, вы сами определяете логику.

**Агент (Agent)** – это отдельное приложение (исполняемая программа Python), которое запускается на машине-исполнителе и связывается с вашим ClearML-сервером. Агент подписывается на одну или несколько очередей: т.е. он "слушает" их и ждёт задач. Когда в очередь поступает новая задача, свободный агент её получает и начинает исполнение.

Чтобы использовать агента, необходимо выполнить такие шаги:

1. **Установка агента**. Агенты распространяются как Python-пакет `clearml-agent`. Его стоит установить на машине, которая будет выполнять задачи (это может быть ваш локальный сервер, удалённый сервер, облачная VM и пр.). Установка:

`pip install clearml-agent`

Убедитесь, что версия агента соответствует версии сервера и SDK (как правило, поддерживается обратная совместимость, но желательно обновлять до актуальной).

2. **Настройка агента**. Перед первым запуском необходимо сконфигурировать подключение агента к серверу (адреса и ключи доступа). Это делается командой:

`clearml-agent init`


Вас спросят аналогичные параметры, что и при clearml-init: URL-ы и ключи. Можно использовать те же самые, что и для SDK (например, скопировать из ~/.clearml.conf). После успешной настройки агент сохранит свою конфигурацию (в файле ~/.clearml.conf или системном). Примечание: Если clearml-agent init запускается на той же машине и под тем же пользователем, что и clearml-init ранее, то можно пропустить этот шаг – агент в таком случае автоматически прочитает существующую конфигурацию SDK.

3. **Запуск агента.** Теперь можно запустить агент как сервис. Базовая команда для старта:

`clearml-agent daemon --queues default`

Этот пример запустит агент, слушающий очередь с именем "default". Если нужно, чтобы один агент обслуживал несколько очередей, перечислите их через запятую: `--queues cpu,gpu`. Ключ `daemon` означает, что агент будет работать в режиме демона (постоянно в фоне, беря новые задачи по мере появления). После запуска агент свяжется с сервером – вы можете увидеть его в веб-интерфейсе (страница **Workers & Queues** или в разделе настройки). Там будет указано имя агента (по умолчанию содержит имя хоста) и список очередей, которые он слушает, а также статус (idle или running).
    
4. **Постановка задачи в очередь**. Существует несколько способов отправить задачу на удалённое выполнение:
    
    - **Через веб-интерфейс**: На странице задачи (которая была ранее запущена локально или сконфигурирована), есть кнопка _Enqueue_ / _Send_. Нажмите её и выберите очередь. Задача сменит статус на _Queued_, и как только агент её подхватит – на _In Progress_. (Важно: чтобы задача могла быть взята агентом, она должна быть в статусе _Draft_ или _Pending_. Если вы уже выполнили задачу локально, имеет смысл **клонировать** её или создать новую задачу с теми же параметрами, но не запускать локально, а сразу отправить в очередь).
        
    - **Через Python SDK**: Можно программно клонировать и запустить задачу. Например, метод `Task.enqueue(task_id, queue_name="gpu")` поместит указанную задачу в очередь "gpu". А метод `task.execute_remotely()` внутри вашего скрипта делает следующее: сохраняет текущую задачу и прекращает локальное выполнение, после чего помещает эту задачу (со всем контекстом) в указанную очередь и автоматически запускается агентом. Таким образом можно написать скрипт, который сам себя отправит на удалённый исполнение.
        
    - **CLI-интерфейс**: Утилита `clearml-task` позволяет из терминала отправлять Python-скрипт на выполнение без необходимости модифицировать код для `Task.init()`. 
    ```bash
	clearml-task --project "Demo Project" --name "Experiment 2" \
    --script train.py --requirements requirements.txt \
    --queue default
    ```    
	
	Данная команда создаст задачу с указанным проектом и именем, загрузит `train.py` как код эксперимента, прикрепит зависимости из `requirements.txt`, и поставит эту задачу в очередь _default_. Запущенный агент подхватит её и выполнит, как если бы вы запускали `train.py` вручную, но при этом всё будет логироваться в ClearML.



Во время выполнения задачи агент изолирует окружение. По умолчанию ClearML Agent создаёт на машине исполняемую **виртуальную среду** (virtualenv) для каждой задачи, устанавливая туда необходимые пакеты (см. вкладку **Execution** -> **Installed Packages** у задачи – там сохраняется список pip-пакетов, который агент будет использовать). Можно настроить агента на использование Docker-контейнеров для задач, если требуются полностью контейнеризованные воспроизводимые среды (в конфиге агента задаётся образ Docker по умолчанию, или он может брать образ, указанный в задаче).

После успешного завершения удалённой задачи её статус станет _Completed_ (или _Failed_ при ошибке). Все логи, метрики и артефакты точно так же будут доступны в интерфейсе. Главное преимущество – вы можете продолжать работать локально, пока тяжёлая задача выполняется на сервере.

**Мониторинг очередей и агентов**: В веб-интерфейсе есть раздел **Queues** и **Workers** (или вкладка на странице Settings). Там можно видеть все очереди, список задач в них и какие агенты их обслуживают. Вы можете вручную переставлять задачи между очередями, останавливать выполнение (отменять задачу) или удалять задачи из очереди.

Таким образом, система "очереди + агенты" реализует диспетчер задач для ML-экспериментов, упрощая запуск на удалённых ресурсах и делая возможным воспроизведение полного конвейера обучения/прогонки моделей по расписанию или по событию.

## Модели

ClearML предоставляет удобный механизм управления моделями машинного обучения, полученными в результате экспериментов. Под **моделью** обычно подразумевается файл с весами нейронной сети или другими обученными параметрами алгоритма. В отличие от произвольных артефактов, модели вынесены в отдельную сущность – **Model Registry** (реестр моделей). Это позволяет отслеживать версионность и происхождение моделей, а также легко их загружать для повторного использования.

Основные возможности работы с моделями в ClearML:

- **Сохранение модели**: Вы можете вручную зарегистрировать файл модели как результат задачи. Обычно это делается по окончании обучения, когда получена финальная или лучшая модель. В SDK есть два подхода:
    
    1. Использовать класс `OutputModel`. Он привязывается к задаче и загружает весовой файл:
	```python
	from clearml import OutputModel
	# допустим, task = Task.current_task() вашей обучающей задачи
	output_model = OutputModel(task=task, name="MyModel")
	output_model.update_weights(weights_filename="best_model.pth")
	```

	Этот код возьмёт файл `best_model.pth` (например, сохранённый PyTorch-модель) и загрузит его на сервер, зарегистрировав как модель с именем "MyModel". Теперь в веб-интерфейсе в разделе **Models** появится новая запись модели, связанная с задачей.

2. Альтернативно, можно вызвать метод задачи `Task.update_output_model()`. Если у вас в задаче обучилась модель и вы сохранили её в файл, просто сделайте:
		
```python
	task.update_output_model(filepath="best_model.pth", model_name="MyModel")
```
	Результат будет аналогичен – модель отправится на сервер


- ClearML также умеет автоматически ловить сохранение моделей для некоторых фреймворков. Например, при использовании Keras, если включен интегратор ClearML, вызов `model.save('model.h5')` может автоматически загрузить `model.h5` как модель в ClearML. Однако, чтобы не полагаться на магию, явное использование `OutputModel` наиболее прозрачно.
    
- **Версии моделей**: Если в рамках одной задачи вы вызываете `update_weights` несколько раз (например, сохраняете промежуточно несколько лучших моделей), ClearML не создаёт новые объекты моделей, а версионирует одну и ту же модель. У каждой модели есть поле **Version** (числовое или строковое), которое вы можете задавать при сохранении. По умолчанию первая сохранённая модель будет версией 1, следующие – 2, 3 и т.д. Это удобно для отслеживания прогресса обучения или обновлений модели. Кроме того, можно **наследовать модель**: создать новую задачу, получить модель из предыдущей как основу, дообучить и сохранить – ClearML сохранит связь версий (например, v2 порождена от v1).
    
- **Просмотр и сравнение**: В разделе **Models** веб-интерфейса вы увидите список всех моделей, зарегистрированных на сервере. Для каждой указано имя, связанная задача (родитель), версия, дату создания, и кто создал. Можно кликнуть на модель и просмотреть её детали: привязанный эксперимент, размер файла, структуру (если указаны метаданные) и т.д. Если модель – это файл определённого формата (например, `.pkl` или `.pt`), ClearML не читает его содержимое (он хранится как blob). Однако вы можете вручную прикреплять к модели **дополнительные артефакты** – например, словарь метрик качества этой модели на тесте, файл с описанием, архитектуру сети в JSON. Всё это можно сделать через `OutputModel` аналогично `upload_artifact`.
    
- **Загрузка и использование моделей**: Главное преимущество регистрации – вы легко можете затем загрузить модель в любом другом скрипте (или production сервисе), обратившись к ClearML по ID модели или имени.

	```python
	from clearml import Model
	model = Model.get(model_id="e3b3bf9f4b834f4db2f3c9cbbd43a123")
	local_path = model.get_local_copy()
	print("Model downloaded to:", local_path)
	```


	Здесь мы получили объект модели по известному ID (его можно взять из UI или сохранить заранее). Метод `get_local_copy()` скачает файл модели на локальный диск (если он ещё не был загружен ранее) и вернёт путь. Далее вы можете загрузить веса в код (например, `torch.load` или `keras.models.load_model`). Также модель можно искать по имени и версии: `Model.get(project_name="Demo Project", model_name="MyModel", version=1)` – это вернёт конкретную версию модели, если она уникально идентифицируется по заданным параметрам.
    
- **Сопоставление моделей и экспериментов**: ClearML связывает модель с задачей её породившей. Это отражается в UI (в модели указано Task ID origin). Обратная связь тоже есть: на странице задачи, которая сохранила модель, будет указано, какая модель получилась на выходе (вкладка **Output Model**). Если затем другая задача использует эту модель как входную (например, fine-tuning), можно отследить цепочку. Такой **Model lineage** помогает понимать, какая версия модели откуда взялась.
    

В совокупности, управление моделями в ClearML упрощает цикл экспериментов: вы не теряете лучшие версии моделей, всегда можете их быстро получить и протестировать, а также иметь централизованное хранилище моделей для команды.

## Datasets

Работа с данными – неотъемлемая часть ML-проекта. ClearML содержит компонент **ClearML Data**, предназначенный для версионирования и хранения датасетов. В рамках Community Edition эта функциональность полностью доступна. **Dataset** в ClearML – это набор файлов (и/или метаданных), объединённых под одним именем и версией, которые можно регистрировать, обновлять и использовать в задачах.

Почему это полезно:

- Вы можете хранить большие исходные данные (например, изображения, CSV, аудио файлы) в удалённом хранилище и версионировать их по аналогии с кодом. Это обеспечивает воспроизводимость экспериментов: любая задача может сослаться на определённую версию датасета и быть уверенной, что получает те же данные.
- Dataset может **наследовать** содержимое другого dataset. Например, вы создали датасет `Images v1`. Затем для новой версии модели вам понадобилось добавить ещё 1000 изображений. Вы можете создать dataset `Images v2`, указав в качестве исходного `v1` и добавив новые файлы. В результате `v2` будет содержать всё из `v1` плюс обновления, при этом в системе хранения это эффективно, так как файлы не дублируются, а происходит ссылка на старые.
- ClearML Data позволяет **объединять датасеты** (например, сделать составной датасет из нескольких, или разбить один на тренировочный/тестовый).
- Каждый dataset можно **задокументировать**: добавить описание, указать источник данных, и прикрепить произвольные артефакты (например, скрипт подготовки данных, статистики по данным и пр.).
- Наконец, dataset всегда можно **скачать локально** для использования – ClearML обеспечит кэширование, чтобы не загружать повторно одинаковые данные.

Для работы с датасетами используется либо CLI утилита `clearml-data`, либо функциональность SDK (модуль `clearml.Dataset`). Рассмотрим пример использования через SDK (Python), создающий простой датасет:

```python
from clearml import Dataset

# Создаем новый датасет
dataset = Dataset.create(dataset_name="cifar_dataset", dataset_project="Datasets/CIFAR10")
# dataset_project используется для организации датасетов по папкам (как проекты для задач)

# Добавляем файл(ы) в датасет
dataset.add_files(path="data/cifar-10-python.tar.gz")

# (Опционально) можно добавить сразу всю папку:
# dataset.add_files(path="data/images_folder", wildcard="*.jpg")

# Загружаем данные на сервер/хранилище
dataset.upload()

# Финализируем (закрываем) версию датасета
dataset.finalize()
```


После выполнения этого кода в ClearML будет зарегистрирован датасет с именем "cifar_dataset". Он принадлежит проекту "Datasets/CIFAR10" (мы используем `/` в названии проекта, чтобы сгруппировать датасеты в разделе Projects, хотя это не обязательно). В состав датасета войдёт файл `cifar-10-python.tar.gz`. Метод `upload()` отправит файл(ы) в хранилище (по умолчанию сервер ClearML использует указанное в конфиге файловое хранилище, например, папку `fileserver` или S3-бакет). `finalize()` зафиксирует версию – после этого датасет получит статус "Published" и будет доступен для использования.

Особенности:

- Каждый вызов `Dataset.create` создаёт **новую версию** датасета. При создании вы можете указать параметр `parent_datasets=[...]`, если хотите унаследовать содержимое одного или нескольких уже существующих датасетов.
- Добавлять файлы можно по одному (`add_file`) или группой (`add_files`), можно исключать некоторые шаблоны, добавлять программно данные (например, из памяти через `dataset.get_local_copy()` и манипуляции).
- Вместо `upload()` можно указать флаг `sync=True` при `add_files`, тогда файлы сразу будут загружаться. Но обычно удобнее сначала добавить, потом разом выгрузить.
- Датасет считается черновиком, пока не вызван `dataset.finalize()`. После финализации содержимое больше не меняется, и версию можно считать готовой для использования в экспериментах.

Использование датасета в задаче эксперимента:

- Чтобы загрузить ранее сохранённый датасет, в коде можно выполнить:
	```python
	dataset = Dataset.get(dataset_name="cifar_dataset", dataset_version=1, 
	dataset_project="Datasets/CIFAR10")
	data_path = dataset.get_local_copy()
	```

	Здесь мы запрашиваем датасет по имени/версии. Метод `get_local_copy()` скачает все файлы датасета (если они ещё не скачаны) и вернёт путь к локальной папке. После этого можно, например, распаковать `cifar-10-python.tar.gz` или прямо работать с файлами.

- ClearML Agent умеет самостоятельно кэшировать и подготавливать датасеты. Если ваша задача объявляет использование датасета (например, `dataset.get_local_copy()` внутри), агент определит зависимости и может заранее скачать данные на машину до запуска основного кода, что экономит время.
- В веб-интерфейсе датасеты отображаются либо в списке проектов (раздел Dataset project), либо в специальном разделе **Datasets** (в новых версиях ClearML есть отдельная страница для управления датасетами). Там можно просматривать состав (список файлов, размер, хеши), различия между версиями, и кто/когда создал версию.

В итоге, функциональность ClearML Datasets помогает следить за данными так же тщательно, как за кодом: любая версия данных, на которой обучалась модель, может быть получена, а изменения между версиями – отслежены.

## Pipelines

Для сложных сценариев, где нужно автоматически связывать несколько задач в последовательность (или граф зависимостей), в ClearML реализованы **пайплайны** (Pipelines). Пайплайн – это по сути workflow из нескольких задач, где выходные данные одних этапов передаются на вход последующим. Это похоже на конвейеры в Airflow, Kubeflow Pipelines, Prefect и других системах оркестрации, но интегрировано непосредственно в ClearML.

Зачем нужны пайплайны:

- Например, у вас есть процесс обучения модели, который состоит из шагов: _подготовить данные_ -> _обучить несколько моделей_ -> _выбрать лучшую_ -> _запустить валидацию на тесте_. Вместо того, чтобы делать один гигантский скрипт или запускать эти шаги вручную по очереди, можно определить пайплайн, который автоматически выполнит их в нужном порядке.
- Пайплайн может выполняться по расписанию или при появлении новых данных, обеспечивая автоматизацию ML процесса (MLOps).
- Каждый шаг пайплайна – это отдельная ClearML задача, со всеми плюсами (логи, метрики, воспроизводимость). ClearML проследит, чтобы шаг 2 не стартовал, пока не завершится шаг 1, и т.д.

Как создавать пайплайны:

1. **Pipeline Controller (кодовый подход)**: ClearML SDK предоставляет класс `PipelineController` (в модуле `clearml.automation`), который позволяет программно составлять пайплайн из существующих задач. Предполагается, что у вас уже есть шаблоны задач для каждого шага (например, вы заранее создали задачи "Data Prep", "Train Model", "Evaluate"). Тогда:

	```python
	from clearml import Task
	from clearml.automation import PipelineController
	
	pipe = PipelineController(name="Training Pipeline", project="ML Pipelines", version="1.0")
	pipe.add_step(name="prepare_data",
	              base_task_project="Examples",
	              base_task_name="Data Preparation")
	pipe.add_step(name="train_model",
	              base_task_project="Examples",
	              base_task_name="Model Training",
	              parents=["prepare_data"])
	pipe.add_step(name="evaluate",
	              base_task_project="Examples",
	              base_task_name="Model Evaluation",
	              parents=["train_model"])
	pipe.start(queue="default")
	```

	В этом примере мы создаём пайплайн с тремя шагами. `add_step` берёт существующую задачу (по проекту и имени) в качестве шаблона для шага. `parents=["prepare_data"]` указывает, что шаг "train_model" должен ждать завершения "prepare_data". Последний вызов `pipe.start()` запускает пайплайн: контроллер создаёт на сервере новую задачу-пайплайн (она будет видна как задача специального типа, например с префиксом "Pipeline") и начинает выдавать задания на очереди. Каждый шаг можно направить на свою очередь (например, тяжелое обучение на GPU, подготовку на CPU) – для этого в `add_step` или `start` можно указать `queue=...` для шагов.
    
    PipelineController будет отслеживать выполнение: если какой-то шаг упал, последующие не запустятся. Результаты каждого шага (метрики, артефакты) можно пробрасывать: например, в приведённом коде второй шаг мог бы принять на вход артефакт, созданный первым шагом. Это настраивается через параметр `parameter_override` и использование конструкций `${parent_task.artifacts.artifact_name}` – более подробно описано в документации ClearML Pipelines.
    
2. **PipelineDecorator (декораторы)**: Альтернативный способ – определять пайплайн с помощью декораторов функций. ClearML предоставляет `PipelineDecorator.component` и `PipelineDecorator.pipeline`. Вы отмечаете функции Python как шаги, а одну функцию как сборку пайплайна, и ClearML сам преобразует это в задачи. Например:

	```python
	from clearml import PipelineDecorator
	
	@PipelineDecorator.component(return_values=["result_data"])
	def step_prepare_data():
	    # ... код подготовки данных ...
	    return prepared_data_path
	
	@PipelineDecorator.component()
	def step_train_model(data_path):
	    # ... код обучения, использует data_path ...
	    return best_model_path
	
	@PipelineDecorator.pipeline(name="Training Pipeline", project="ML Pipelines")
	def pipeline_flow():
	    data = step_prepare_data()
	    model = step_train_model(data)
	```


	Вызов `pipeline_flow()` приведёт к тому, что ClearML автоматически создаст задачи для `step_prepare_data` и `step_train_model`, свяжет их (передавая выход `data` как параметр во второй шаг) и запустит на выполнение. Этот способ удобен, когда пайплайн описывается целиком в коде. Внутри функций можно использовать обычный ClearML SDK для логирования, или вообще не использовать – тогда ClearML просто обернёт их выполнение.
	    
	Оба подхода (PipelineController и PipelineDecorator) приводят к созданию сущности _Pipeline_ на сервере. В интерфейсе ClearML появится визуальное представление пайплайна: граф узлов (шагов) со статусами, и возможностью провалиться внутрь каждого шага (открыть соответствующую задачу).
    

- **Управление пайплайном**: Выполняющийся пайплайн можно мониторить в UI, останавливать, перезапускать шаги. Если вы версию пайплайна изменили (например, обновили шаблон задачи или код), можно запустить новую версию (обновив параметр `version` или имя). Старые пайплайны сохраняются, их результаты тоже доступны.
    
- **Пайплайн как задача**: Контроллер пайплайна сам является задачей ClearML. Это означает, что его можно, например, поставить в очередь на выполнение (если вы запускаете пайплайн из скрипта, который, в свою очередь, хотите выполнять агентом). Такой гибкий подход позволяет строить многоуровневые оркестрации.
    

В контексте Community Edition, пайплайны дают возможность без дополнительного ПО реализовать полноценный **workflow orchestration** для ваших ML-процессов. Например, можно настроить дневной запуск пайплайна, который собирает свежие данные, переобучает модель и сохраняет новый результат. Все это будет прозрачно логироваться и контролироваться ClearML.










## Пример использования ClearML для эксперимента

Рассмотрим практический пример полного цикла эксперимента с использованием ClearML. В этом примере обучим модель для прогнозирования выживаемости пассажиров _Titanic_ и покажем, как отслеживать данные, метрики и модели с помощью ClearML. Предполагается, что у нас уже есть датасет Titanic (например, файл `titanic.csv`).

**Шаг 1. Инициализация новой задачи.** Для начала импортируем библиотеку и создаём задачу в ClearML:

```python
from clearml import Task, Logger  
task = Task.init(     
	project_name="ClearML_Test",      
	task_name="Titanic Survival Prediction",      
	tags=["CatBoost", "RandomSearch"] )
```


Этот код создаёт новую задачу **Titanic Survival Prediction** в проекте **ClearML_Test**. В консоли появится ссылка на веб-интерфейс эксперимента – можно перейти по ней или найти задачу через интерфейс ClearML вручную. Каждый раз при выполнении `Task.init` создаётся новая задача (новый эксперимент) с указанными именем и тегами. Если указанный проект (например, "ClearML_Test") не существует, ClearML автоматически создаст его. (Однако рекомендуется заранее создавать проекты для структуры.)

После инициализации ClearML начинает автоматически логировать практически все происходящее в коде. В веб-интерфейсе в разделе **Execution** можно увидеть запускаемый код, а также список подключённых библиотек и их версий. Если работа осуществляется в ноутбуке, ClearML также сохранит копию всего ноутбука на сервер (в виде HTML) – ссылку можно найти на вкладке **Artifacts** эксперимента. Помимо этого, любой вывод в консоль (stdout/stderr) и логи популярных ML-библиотек будут перехвачены и сохранены. С этого момента эксперимент отслеживается системой.

**Шаг 2. Загрузка данных и сохранение датасета как артефакта.** Загрузим исходные данные и сразу зарегистрируем их в системе:

```python
import pandas as pd  
fpath = "titanic.csv" 
df_raw = pd.read_csv(fpath) 
task.upload_artifact(name="data.raw", artifact_object=fpath)
```

Мы читаем CSV-файл с данными Titanic в DataFrame `df_raw`. Одновременно через метод `upload_artifact` сохраняем исходный датасет на сервер ClearML как артефакт с именем **data.raw**. Мы передали путь к файлу, и ClearML загрузил файл и прикрепил к текущей задаче. Все загруженные артефакты отображаются на вкладке **Artifacts** в интерфейсе эксперимента – оттуда их можно скачать в любой момент.

> **Примечание:** Если вместо файла указать путь к папке, ClearML рекурсивно заархивирует содержимое папки в zip-файл и сохранит его как единый артефакт.

**Шаг 3. Разведочный анализ данных (EDA).** Проведём небольшой первичный анализ данных и сохраним результаты в виде артефактов:

```python
# базовые статистики датасета 
task.upload_artifact(     
	name="eda.describe.object",    
	artifact_object=df_raw.describe(include=object) ) 
task.upload_artifact(     
	name="eda.describe.number",
	artifact_object=df_raw.describe(include=np.number) )
```


Здесь мы воспользовались методом `describe()` из pandas, чтобы получить статистику по категориальным признакам (`include=object`) и числовым признакам (`include=np.number`). Результат (таблицы с описательными статистиками) мы сразу сохранили как артефакты с именами **eda.describe.object** и **eda.describe.number**. ClearML способен сохранять в виде артефактов практически любые Python-объекты. В данном случае JSON-представление DataFrame с описанием данных сохранено на сервере, и его можно просмотреть прямо в веб-интерфейсе (артефакт откроется как таблица).

**Шаг 4. Визуализация данных.** Построим несколько графиков для визуального анализа, убедившись, что ClearML их зафиксирует:

```python
import seaborn as sns 
import matplotlib.pyplot as plt  
sns.pairplot(df_raw, hue="Survived") 
plt.title("Pairplot") 
plt.show()
```


Мы строим парные графики (`pairplot`) для признаков датасета, раскрашенные по целевому классу _Survived_. Вызов `plt.show()` в ноутбуке гарантирует отображение графика. ClearML автоматически улавливает и сохраняет все графики, построенные с помощью Matplotlib (Seaborn использует Matplotlib под капотом). Эти графики можно найти в интерфейсе на вкладке **Plots** текущего эксперимента. Таким образом, любые визуализации, созданные в ходе эксперимента, будут доступны для последующего анализа через веб-интерфейс.

**Шаг 5. Предобработка данных.** Очистим датасет от лишних колонок, приведём типы и разобьём на обучающую и тестовую выборки, сохранив их:

```python
from sklearn.model_selection 
import train_test_split import numpy as np  
# удаляем неинформативные колонки 
df_preproc = df_raw.drop(columns=["PassengerId", "Name", "Ticket"]) 
# приводим категориальные признаки к строковому типу 
for col in ["Sex", "Cabin", "Embarked"]:    
	df_preproc[col] = df_preproc[col].astype(str) 
	task.upload_artifact(name="data.preproc", artifact_object=df_preproc)  

# разбиение на train/test 
train_df, test_df = train_test_split(df_preproc, test_size=0.33, random_state=42) task.upload_artifact(name="data.train", artifact_object=train_df) task.upload_artifact(name="data.test", artifact_object=test_df)
```


На этапе предобработки мы удалили несколько неиспользуемых признаков (`PassengerId`, `Name`, `Ticket`), а также преобразовали категориальные колонки `Sex`, `Cabin`, `Embarked` в строковый тип (это необходимо для корректной работы модельного фреймворка, например CatBoost, с данными). После этого весь получившийся датафрейм `df_preproc` загружается как артефакт **data.preproc**. Затем мы разделяем данные на обучающую и тестовую выборки и загружаем их отдельно как **data.train** и **data.test**.

Мы создали три новых датасета и все три отправили в ClearML как артефакты. Обратите внимание, что в вызове `upload_artifact` мы передавали напрямую объекты pandas DataFrame. ClearML «понимает» этот формат данных: в интерфейсе для таких артефактов можно просмотреть фрагмент содержимого таблицы (первые строки и столбцы).

> **Совет:** Для DataFrame существует метод `Task.register_artifact`. В отличие от `upload_artifact`, при использовании `register_artifact` ClearML будет отслеживать изменения объекта (например, DataFrame) в реальном времени и синхронизировать обновлённые данные с сервером.

**Шаг 6. Обучение модели.** Теперь обучим простую модель классификации – используем градиентный бустинг CatBoost на наших данных:

```python
from catboost import CatBoostClassifier, Pool 
from sklearn.metrics import roc_auc_score  
# разделение признаков и целевой переменной 
X_train = train_df.drop(columns=["Survived"]) 
y_train = train_df["Survived"]  
model = CatBoostClassifier(silent=True) 
model.fit(X_train, y_train, cat_features=["Sex", "Cabin", "Embarked"])
```


Мы инициализировали `CatBoostClassifier` и обучили его на тренировочных данных (`train_df`). Параметр `cat_features` указывает какие признаки считать категориальными. ClearML автоматически отследил процесс обучения: для популярных библиотек (таких как CatBoost) платформа перехватывает вывод обучения и логирует основные метрики. После выполнения этого шага на вкладке **Scalars** (Графики скаляров) в веб-интерфейсе вы сможете увидеть кривую обучения – изменение функций потерь и качества на каждой итерации бустинга, если CatBoost выводил такую информацию. Таким образом, без дополнительного кода все ключевые показатели обучения модели уже сохранены в системе.

**Шаг 7. Поиск гиперпараметров с логированием метрик.** Результаты первой модели можно улучшить подбором гиперпараметров. Продемонстрируем, как в ClearML удобно логировать метрики разных экспериментов. Попробуем случайным поиском протестировать несколько комбинаций гиперпараметров CatBoost и занести результаты на графики:

```python
from sklearn.model_selection import ParameterSampler

# Определяем сетку возможных значений гиперпараметров
param_grid = {
    "depth": [4, 5, 6, 7, 8],
    "learning_rate": [0.1, 0.05, 0.01, 0.005, 0.001],
    "iterations": [30, 50, 100, 150]
}

# Подготовим данные для оценки качества
X_test = test_df.drop(columns=["Survived"])
y_test = test_df["Survived"]

# Получаем текущий логгер для задачи
log = Logger.current_logger()

# Переменные для отслеживания лучшей модели
best_score = 0
best_model = None
iteration = 0

# Случайным образом выбираем 50 комбинаций гиперпараметров из сетки
for params in ParameterSampler(param_grid, n_iter=50, random_state=42):
    # Обучаем модель с данной комбинацией параметров
    model = CatBoostClassifier(**params, silent=True)
    model.fit(X_train, y_train, cat_features=["Sex", "Cabin", "Embarked"])
    
    # Оцениваем модель на тестовом наборе
    test_scores = model.eval_metrics(
        Pool(X_test, y_test, cat_features=["Sex", "Cabin", "Embarked"]), 
        metrics=["Logloss", "AUC"]
    )
    test_logloss = round(test_scores["Logloss"][-1], 4)
    test_auc = round(test_scores["AUC"][-1] * 100, 1)
    # Оцениваем модель на обучающем наборе
    train_scores = model.eval_metrics(
        Pool(X_train, y_train, cat_features=["Sex", "Cabin", "Embarked"]), 
        metrics=["Logloss", "AUC"]
    )
    train_logloss = round(train_scores["Logloss"][-1], 4)
    train_auc = round(train_scores["AUC"][-1] * 100, 1)
    
    # Если качество на тесте улучшилось — сохраняем новую лучшую модель и логируем метрики
    if test_auc > best_score:
        best_score = test_auc
        best_model = model
        # Логируем метрики в виде скалярных графиков
        log.report_scalar(title="Logloss", series="Test", iteration=iteration, value=test_logloss)
        log.report_scalar(title="Logloss", series="Train", iteration=iteration, value=train_logloss)
        log.report_scalar(title="ROC AUC", series="Test", iteration=iteration, value=test_auc)
        log.report_scalar(title="ROC AUC", series="Train", iteration=iteration, value=train_auc)
        iteration += 1

# Сохраняем несколько итоговых показателей в лог в виде констант:
log.report_single_value("Best ROC AUC", best_score)
log.report_single_value("Best Logloss", test_logloss)
log.report_single_value("Train Rows", X_train.shape[0])
log.report_single_value("Test Rows", X_test.shape[0])
log.report_single_value("Features", X_train.shape[1])
log.report_single_value("Positive Ratio (Train)", round(y_train.mean(), 3))
log.report_single_value("Positive Ratio (Test)", round(y_test.mean(), 3))

```

В этом коде мы определяем сетку гиперпараметров `param_grid` (различные значения глубины деревьев, скорости обучения, числа итераций) и случайным образом выбираем 50 наборов параметров для теста с помощью `ParameterSampler`. Для каждой комбинации заново обучаем модель CatBoost на тренировочных данных, затем оцениваем качество модели на тестовых и тренировочных данных (считаем метрики Logloss и AUC ROC). Мы отслеживаем лучшую модель по метрике AUC на тесте. Если текущая модель оказалась лучшей, мы обновляем `best_model` и логируем ее метрики: через `log.report_scalar` отправляем значения Logloss и ROC AUC для теста и обучения. Мы используем переменную `iteration` в качестве индекса итераций на графике, увеличивая её каждый раз, когда находим новый лучший результат. Таким образом, в ClearML на вкладке **Scalars** появятся 2 графика: _Logloss_ и _ROC AUC_, на которых отображаются точки (или линии) только для лучших найденных моделей по мере продвижения поиска.

После завершения цикла мы также логируем несколько итоговых значений через `report_single_value`: наилучшее значение AUC, соответствующий ему Logloss, а также размеры выборок и долю положительных классов в train/test. Эти значения сохраняются как отдельные постоянные параметры эксперимента (их можно увидеть в интерфейсе как таблицу Constant metrics или в деталях задачи). ClearML поддерживает множество видов отчетов и метрик, помимо скалярных графиков – можно логировать текстовые данные, таблицы, изображения, интерактивные графики и т.д., но в данном примере мы ограничились наиболее распространенными (см. документацию по `Logger` для подробностей).

**Шаг 8. Сохранение лучшей модели.** После завершения поиска у нас в переменной `best_model` хранится модель с наилучшим качеством. Сохраним эту модель на диск:

`best_model.save_model("best_model.cbm")`

Здесь мы явно сохраняем модель CatBoost в локальный файл `best_model.cbm`. Однако ClearML автоматически обнаруживает факт сохранения модели и регистрирует этот файл на сервере как итоговый артефакт типа "модель". В веб-интерфейсе в проекте на вкладке **Models** (Модели) появится новая запись – сохранённая модель для нашей задачи. Таким образом, все модели, полученные в экспериментах внутри одного проекта, централизованно собираются в разделе моделей проекта, что удобно для последующего выбора лучшей версии модели. (Заметим, что есть и программный способ явно сохранить модель в систему ClearML через SDK, см. документацию, однако в нашем случае платформа сделала это автоматически.)

**Шаг 9. Завершение эксперимента.** После окончания всех операций закроем задачу:

`task.close()`

## Теперь эта же задача, с реализацией через pipline
